---
title: "Informedb Issues Analysis"
author: "Liam Whitenack"
date: "2021-06-25"
output: html_document
runtime: shiny
---
#### Mentors: John Klaczynski, Peter Morrisey
```{r setup, include=FALSE}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(infer))
suppressPackageStartupMessages(library(modelr))
suppressPackageStartupMessages(library(broom))
suppressPackageStartupMessages(library(rlang))
suppressPackageStartupMessages(library(plotly))
suppressPackageStartupMessages(library(shiny))
suppressPackageStartupMessages(library(shinythemes))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(readr))
suppressPackageStartupMessages(library(datasets))
suppressPackageStartupMessages(library(anytime))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(scales))
# Change this line if you want to use other data
Jira_tidy <- read_csv("Informedb_tidy.csv")
```
```{r reference_chunk, eval=FALSE, include=FALSE}
# the ui should contain the input and the display code
ui <- fluidPage(
  
)
# the server should contain the code for whatever uses the input
server <- function(input, output) {
  
}

 #this code doesn't need to be edited
shinyApp(ui = ui, server = server)
```


## Problem Statement
This project was made to analyze SimVentions' Reliability regarding the Informedb project using the reports on Jira.  
By opening the project Informedb (INF) on https://jira.dev.simventions.com/secure/Dashboard.jspa, you can look at the original project. Informedb was chosen by my mentors because of its extensive history.  

It's important to note that Informedb is a legacy project and is now called Enterprise (EN) and stored on a separate project board.  

Several "Software Quality Metrics" were requested, all of which have to be estimated to a degree Each parameter above was requested in this PowerPoint:    https://simventions.sharepoint.us/:p:/r/EC/Shared%20Documents/NSWCDD%20Software%20Quality%20Metrics_12APR21.pptx?d=w15810cbc0c744094ace80239877ff2e4&csf=1&web=1&e=kPal7h  
  
This project is made from exporting the data from Jira and using RStudio to only use the rows and columns necessary. Only the rows which contained the Issue Type "Bug" are being used. The "Repair Time" parameter was found by subtracting the day the issue was made from the day the issue was resolved. This is an estimation and not an ideal calculation, since the issue has not started being repaired until the issue was moved into Jira.  

##### Note: "R1" indicates that the bug is a high-priority fix and "R4" indicates that the bug is a low-priority fix

```{r stats, eval=FALSE, include=FALSE}
summary_stats <- read_csv("summary_Statistics.csv")
# the ui should contain the input and the display code
ui <- fluidPage(
  tableOutput("stats")
)
# the server should contain the code for whatever uses the input
server <- function(input, output) {
  output$stats <- renderTable(summary_stats)
}

 #this code doesn't need to be edited
shinyApp(ui = ui, server = server)
```

## Defect Trends Histogram  
This histogram summarizes Informedb's bug reporting and updating. "Date Created" is the day that the bug was reported in Jira. "Date Updated" is the last day that the bug was edited in Jira. "Date Resolved" is the last time the bug was edited *if* it was marked as resolved. 
  
  
```{r histogram, echo=FALSE}
# create ui to display
ui <- fluidPage(
  
  #make separate panels so that the project can be viewed side by side
  
  sidebarLayout(
    
    # start a panel with interactive buttons
      
    sidebarPanel(
      # create a dropdown list with the names of the columns that we're looking to examine
      
      selectInput(
        inputId = "action",
        label = "Parameters",
        choices=c("Date Created", "Date Updated", "Date Resolved"),
        selected = "Date Created"
      ),
      
      # create a slider that chooses the day the histogram looks at
      
      sliderInput(
        inputId = "start_date_resolved", 
        label = "Choose a start date", 
        value = as.Date(max(Jira_tidy$`Date Created`)-365), 
        min = as.Date(min(Jira_tidy$`Date Created`)), 
        max = as.Date(max(Jira_tidy$`Date Created`)-182)
      ),
      
      # create a slider that chooses the amount of bins on the histogram
      
      sliderInput(inputId = "bins", label = "Choose the number of bins", value = 12, min = 6, max = 60, step = 6),
    ),
  
  #start a main panel to display the graphs we want
  
  mainPanel(
    
    #plot the histogram made in the server function
    
    plotOutput("histogram")
  )
  )
)

#create the server function responsible for reacting to the different sliders

server <- function(input, output) {
  
  # create my histogram
  output$histogram <- renderPlot({
    # use ggplot to make a plot
    ggplot()+
      geom_histogram(
      aes(
          #use the user-input parameter chosen as the x value
        x = (as.POSIXct(array(c(data.matrix((Jira_tidy[,input$action]))))*24*60*60, origin="1970-01-01")),
          # color by priority
        fill = Jira_tidy$Priority
      ), #use the user input for bins
      bins = input$bins
  )+ 
      # the xlim is determined by the user, using input$start_date_resolved, 
      # so that they can determine how much time they want to look at. 
      # The xmax is the max of the data being looked at.
  xlim(as.POSIXct(input$start_date_resolved),
max((as.POSIXct(array(c(data.matrix((Jira_tidy[,input$action]))))*24*60*60, origin="1970-01-01")))) +
      #rename the labels of the graph
  xlab(input$action)+
  ylab("Count") +
  labs(fill = "Priority", title = "Defect Trends")
  })
}

# print all to the screen

shinyApp(ui = ui, server = server)
```  

## Defect Trends Scatterplot  
This scatterplot lists the day that each issue was created/updated/resolved and compares the "Time Spent"/"Repair Time".  

The difference between "Repair Time" and "Time Spent" is that "Repair Time" measures the difference between the date resolved and the date created (in days) and the "Time Spent" measures the difference between the date updated and the date created (in days). In other words, repair time only includes the projects that were marked as "resolved".  

If you would like distinguish between different groups of issues, you can color each point by a certain attribute.
  
  
```{r scatterplot, echo=FALSE}
# the ui should contain the input and the display code
ui <- fluidPage(
  sidebarLayout(
    sidebarPanel(
      
      # create three lists of column names to be used as variables
      
      selectInput(
        inputId = "xvar",
        label = "X Variable:",
        choices=c("Date Created",  "Date Updated",  "Date Resolved"),
        selected = "Date Created"
      ),
      
      selectInput(
        inputId = "yvar",
        label = "Y Variable:",
        choices=c("Time Spent", "Time Spent (Without Outliers)", "Repair Time", "Repair Time (Without Outliers)"),
        selected = "Time Spent"
      ),
      
      selectInput(
        inputId = "color",
        label = "Color By:",
        choices=c("Priority", "Status", "Issue_Type", "Assigned_to_a_Developer", "Reported_by_a_Developer"),
        selected = "Priority"
      )
    ),
    
    # plot our graph
    
    mainPanel(
      plotOutput("scatterplot")
    )
  )
)
# the server should contain the code for whatever uses the input
server <- function(input, output) {
  
  # create the scatterplot
  
  output$scatterplot <- renderPlot({
    ggplot()+
      geom_point(
        aes(
          
          # the three different selectInput() functions should determine the axis variables
          
          x = (as.POSIXct(array(c(data.matrix((Jira_tidy[,input$xvar]))))*24*60*60, origin="1970-01-01")),
          y = array(c(data.matrix((Jira_tidy[,input$yvar])))),
          color = array(c(as.matrix(Jira_tidy[,input$color]))),
          na.rm = TRUE
        ), 
        
      ) +
      xlim(
        min((as.POSIXct(array(c(data.matrix((Jira_tidy[,input$xvar]))))*24*60*60, origin="1970-01-01")), na.rm = TRUE),
        max((as.POSIXct(array(c(data.matrix((Jira_tidy[,input$xvar]))))*24*60*60, origin="1970-01-01")), na.rm = TRUE)) +
      ylim(
        min(array(c(data.matrix((Jira_tidy[,input$yvar])))), na.rm = TRUE),
        max(array(c(data.matrix((Jira_tidy[,input$yvar])))), na.rm = TRUE)
      ) +
      xlab(input$xvar)+
      ylab("Days") +
      labs(color = input$color, title = "Defect Scatterplot") +
      geom_smooth(
        aes(
          x = ((as.POSIXct(array(c(data.matrix((Jira_tidy[,input$xvar]))))*24*60*60, origin="1970-01-01"))),
          y = array(c(data.matrix((Jira_tidy[,input$yvar]))))
        )
      )
  })
}

 #this code doesn't need to be edited
shinyApp(ui = ui, server = server)
```  

## Time Spent Histogram  
This histogram reflects the distribution of "Repair Time" and "Time Spent".  
  
  
```{r time_spent_hist, echo=FALSE}
# the ui should contain the input and the display code
ui <- fluidPage(
  sidebarLayout(
    sidebarPanel(
      selectInput(
        inputId = "time",
        label = "Choose your Column:",
        choices=c("Time Spent", "Repair Time"),
        selected = "Date Created"
      ),
      sliderInput(
        inputId = "max_time", 
        label = "Choose a range:", 
        value = (max(Jira_tidy$`Time Spent`)-500), 
        min = 31, 
        max = (max(Jira_tidy$`Time Spent`))
      ),
      sliderInput(
        inputId = "breaks", 
        label = "Choose the number of bins:", 
        value = 10, 
        min = 5, 
        max = 20
        ),
    ),
    mainPanel(
      plotOutput("histy")
    )
  )
)
# the server should contain the code for whatever uses the input
server <- function(input, output) {
  output$histy <- renderPlot({
  ggplot()+
    geom_histogram(aes(x = array(c(data.matrix(Jira_tidy[,input$time]))), fill = Jira_tidy$Priority), bins=input$breaks) +
                     xlim(0, as.numeric(input$max_time)) +
      xlab("Days")
  })
}

 #this code doesn't need to be edited
shinyApp(ui = ui, server = server)
```

## Summary Statistics
This table allows a clear look at each parameter. Some of the columns can be redundant when the rows are grouped differently, but changing the configuration can provide useful insights.
  
```{r summary_stats, echo=FALSE}
# the ui should contain the input and the display code
ui <- fluidPage(
  sidebarLayout(
    sidebarPanel(
      selectInput(
        inputId = "group",
        label = "Group by:",
        choices=c("Priority", "Status", "Issue_Type", "Assigned_to_a_Developer", "Reported_by_a_Developer"),
        selected = "Priority"
      ),
    ),
    mainPanel(
      tableOutput("sum_stats")
    )
  )
)
# the server should contain the code for whatever uses the input
server <- function(input, output) {
  output$sum_stats <- renderTable({
  Jira_tidy %>%
  group_by_(input$group) %>%
    summarise( 
      `Defects` = n(), 
      # count the number of rows that were created in the last 28 days
      MTTR = (mean((`Repair Time`), na.rm = TRUE)), 
      # Repair time average
      Closed = sum(failed_fix), 
      # the number of "closed" issues i.e. issues that were opened 
      # and then closed because they couldn't be fixed
      Open = sum(open),
      # count the number of rows that aren't closed or resolved
      Assigned = sum(assigned),
      # count the number of rows that have an assignee
      DRE = scales::percent(sum(completed) / n()), 
      # count the number of rows marked as completed
      `Assign Percent` = scales::percent(sum(assigned)/n())
    )
  })
}

 #this code doesn't need to be edited
shinyApp(ui = ui, server = server)
```  


### Parameters:

* Defects:  
Total Number of reported bugs.  

* MTTR â€“ Mean time to repair:  
This parameter is calculated by finding the mean of the repair time. Repair time should be calculated by subtracting the date the issue was put "in progress" from the day the project was resolved. Unfortunately, This parameter is found using the day the issue was made because the day the issue was put "in progress" is not available.  

* Closed:  
Number of defects that were determined by the team to be left alone without being resolved. These bugs were then moved to the "Closed" column.  

* Open:  
The number of bugs left open without being finished.

* Assigned:  
The number of bugs that were given an assignee.

* DRE:  
DRE = (number of defects resolved/number of defects found) * 100.

* Assign Percent:  
The Percent of bugs that were given an assignee.

## Reflection
It is important to note that no number or "quality metric" should be used to quantify and judge any employee's or team's work. Using a blanket statement to attribute statistics to a complex system is dangerous. However, useful insights and improvements can be made from relevant data.  

This analysis is still in progress and it would be hasty to come to any conclusion given that I am in a data-poor situation. A new extension is currently being added to Jira so that more relevant data can be exported.  

Unfortunately, there are some signs that there are some errors in the reporting process. For instance, a very large portion of issues were all updated on the same day. Did Informedb have a few extremely productive days? Or is there a chance that many projects were already completed, but marked as incomplete, then all moved on the same day?  
The best insight I can offer with the current analysis is that when a project is assigned, the project is finished *so* much more efficiently. This could be because Assigned projects have already been started, because assigned projects were deemed a higher priority, or for many other reasons I haven't listed. However, if a bug needs to be addressed, the best way to make sure that it gets finished is to make sure someone is assigned to it.  

This project feels raw largely because it does not indicate the quality of the code. Without some way to connect the bugs to their section of code they work on, it would be impossible for anyone to know from Jira if the Informedb code produces bugs or not.  

## Application  
Recording information timely and accurately can help SimVentions give accurate and impressive reports to the military when the team is trying to earn contracts. Reflecting that the team can accurately reflect its code coverage and defect trends shows to another party that SimVentions is capable of impressing.

More to come!